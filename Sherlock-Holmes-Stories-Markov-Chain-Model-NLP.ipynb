{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherlock Holmes Stories Markov Chain Model NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The purpose of this model is to generate text that is similar to `Shelock Holmes Stories` using `Markov Chains` approach. To build a Markov Chain we need states that will be words of the text and transitions that are the probabilities of going among the states. To find the transition probabilities we traverse the text and find the conditional probability of each word following another. So basically, the probability that the next word (state) will be `j` given that the current word (state) is `i` based on the adjacency list. We can cosider the transitions as statistical properties of the text data and because of this the model will produce random text which is similar to the original text. To generate the text, the model will do a walk (traverse by following the transition probabilities) from a innitial optional (given by us) state (word) and go to the next states. Each state (word) we visited will be part of our text. This can be considered a directed graph with weights traversal, that each node is a state (word) and the edges will define the transitions (probability to be adjacency)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tokenizer\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fixing NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Shelock Holmes stories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def read_all_stories(path: str) -> list:\n",
    "    stories: list = []\n",
    "    \n",
    "    for _, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            with open(path + file) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip() # remove spaces around the string\n",
    "                    # Each story in the dataset has the LICENSE\n",
    "                    # in the end of the file which will be ignored\n",
    "                    if line == \"----------\": break \n",
    "                    if line != '': stories.append(line)\n",
    "                        \n",
    "    return stories\n",
    "\n",
    "story_path: str =  \"./sherlock-stories-data-set/\"\n",
    "\n",
    "stories: list = read_all_stories(story_path)\n",
    "\n",
    "assert len(stories) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the data\n",
    "\n",
    "Clean dataset required for `NLP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: list) -> list:\n",
    "    cleaned_data: list = []\n",
    "    for text in data:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", text)\n",
    "        tokens: list = word_tokenize(text)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_data += words\n",
    "    return cleaned_data\n",
    "\n",
    "cleaned_stories: list = clean_data(stories)\n",
    "\n",
    "assert len(cleaned_stories) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markov Model\n",
    "\n",
    "The function will accept also the n_gram which will be used to define number of words in a state (sequence of n words). This will give more context so, the text produced by this model will probably be similar and make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_markov_model(cleaned_stories: list, n_gram: int = 1) -> dict:\n",
    "    markov_model: dict = {}\n",
    "        \n",
    "    for i in range(len(cleaned_stories) - n_gram - 1):\n",
    "        \n",
    "        current_state: str = \"\"\n",
    "        next_state: str = \"\"\n",
    "        \n",
    "        for j in range(n_gram):\n",
    "            current_state += cleaned_stories[i + j] + \" \"\n",
    "            next_state += cleaned_stories[i + j + n_gram] + \" \"\n",
    "            \n",
    "        current_state = current_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        \n",
    "        if current_state not in markov_model:\n",
    "            markov_model[current_state] = {}\n",
    "            markov_model[current_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[current_state]:\n",
    "                markov_model[current_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[current_state][next_state] = 1\n",
    "    \n",
    "    # Calculating transition probabilities\n",
    "    for current_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[current_state][state] = count / total\n",
    "        \n",
    "    return markov_model\n",
    "\n",
    "markov_model: dict = create_markov_model(cleaned_stories, 2)\n",
    "\n",
    "assert len(markov_model.keys()) > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'said i': 0.07017543859649122, 'he has': 0.07017543859649122, 'oh yes': 0.07017543859649122, 'i have': 0.07017543859649122, 'i thought': 0.07017543859649122, 'i ejaculated': 0.07017543859649122, 'what do': 0.07017543859649122, 'i exclaimed': 0.07017543859649122, 'am i': 0.05263157894736842, 'my previous': 0.05263157894736842, 'if i': 0.05263157894736842, 'and tell': 0.05263157894736842, 'that i': 0.05263157894736842, 'i fear': 0.07017543859649122, 'you are': 0.05263157894736842, 'it is': 0.05263157894736842}\n"
     ]
    }
   ],
   "source": [
    "# All transitions from `dear holmes` state\n",
    "print(markov_model['dear holmes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'forest which': 0.12903225806451613, 'brain of': 0.12903225806451613, 'cesspool into': 0.0967741935483871, 'emporium proved': 0.12903225806451613, 'grimpen mire': 0.0967741935483871, 'city so': 0.0967741935483871, 'rich corporations': 0.0967741935483871, 'developments are': 0.12903225806451613, 'trunk of': 0.0967741935483871}\n"
     ]
    }
   ],
   "source": [
    "# All transitions from `that great` state\n",
    "print(markov_model['that great'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_model: dict, start: str, length: int = 100) -> str:\n",
    "    story: str = start\n",
    "    current_state = start\n",
    "    next_state = {}\n",
    "    \n",
    "    for _ in range(length):\n",
    "        next_state = random.choices(list(markov_model[current_state].keys()),\n",
    "                                    list(markov_model[current_state].values()))[0]\n",
    "        \n",
    "        current_state = next_state\n",
    "        \n",
    "        story += current_state + \" \"\n",
    "        \n",
    "    return story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating some random stories with different innitial states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sherlock holmeswhom i was not on it hes holding off the walls and yet those strange peaked roofs and peep in at the other end which was found in the dead mans hand and almost danced with excitement in his manner but on the day that sir robert has not returned i must find the story in the first signs of a murderous attack upon him nor would he do come to consult with the blue smoke curling up from him and to serve the purpose must have been generally successful then you begin to wonder i believe shoscombe prince and the derby the sporting interest of his case for it made me rather more lax than befits a medical man you know whom they loved and it was the children say at last in a dry rasping tone the best this last statement appeared to me i heard something of the world that it was no delusion one of them were destined to travel it has appeared to be sheltering themselves from me i dont know his address no except that it was only after her just now but it is coming to consult even at a distance fastened a  300\n"
     ]
    }
   ],
   "source": [
    "# Story 1\n",
    "print(generate_story(markov_model, \"sherlock holmes\"), 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the caseis clear that mrs hudson and kindly send one of the older man is aware that i was looking for miss rachel with which we had hoped that perhaps you will have the kindness to place it in both hers in an hour i waited with some curiosity as to come and the billet was such a blind but why should he drug his own and it is also my old friend watson in she is after and she is brooding and malicious eyes had devised a safe which stood two of them were smoking cigars and coffee a few details about the arrival of her people but if you had shared his fortunes and had the place immediately afterwards i went round and examined each and all further investigation has served a purpose what is the meaning of it but i dont mind telling you mr sherlock holmes was standing smiling on the next morning but what in heavens name was strange to me to drink then she despised me as a doctor eh cried he much excited have you your very excellent and so lonesome that i thought you knew who i am but you are stronger she  500\n"
     ]
    }
   ],
   "source": [
    "# Story 2\n",
    "print(generate_story(markov_model, \"the case\"), 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dear holmesmy previous letters and telegrams which were handed unto the holy joseph smith at palmyra we have come to our needs if you would find within the grounds the lake to which i have a curious collection very curious and the story was evidently the bearer of a kitchen garden the inner cartilage in all essentials it was the same terrible winter darkly the shadow lay upon the inside and get away just to the north of oporto the proceedings it is you like mr holmes i can understand how you attained this result simply by having the heart to band themselves together against their oppressors rumours had reached the bottom of the box the professor was buried in his flight had dropped his cravat and his worn boots he was not the mere fright of a man whose patriotism is beyond suspicion he would change his name it appeared less funny than he could have happened and finally what dr thorneycroft huxtable of the priory is a guilty reason for it the adventures of sherlock holmes requests for they never fired upon us and in recovering my horse you would do better to clear the matter up ah martha  180\n"
     ]
    }
   ],
   "source": [
    "# Story 3\n",
    "print(generate_story(markov_model, \"dear holmes\"), 180)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "6591b298595e9596869d5713917120921e7e47faf38318787b166a3cc58ba2f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
